/*
 *     Generated by class-dump 3.3.4 (64 bit).
 *
 *     class-dump is Copyright (C) 1997-1998, 2000-2001, 2004-2011 by Steve Nygard.
 */

#pragma mark Typedef'd Structures

typedef struct {
    void *_field1;
    void *_field2;
    void *_field3;
} CDStruct_90f67059;

typedef struct {
    int _field1;
    int _field2;
} CDStruct_1ef3fb1f;

#pragma mark -

/*
 * File: /Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS5.0.sdk/System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices
 * UUID: FC2567D7-62B1-3F3E-AE52-53DCCB8B2979
 * Arch: arm v7 (armv7)
 *       Current version: 1.0.0, Compatibility version: 1.0.0
 *       Minimum iOS version: 5.0.0
 *
 *       Objective-C Garbage Collection: Unsupported
 */

@protocol NSObject
- (BOOL)isEqual:(id)arg1;
- (unsigned int)hash;
- (Class)superclass;
- (Class)class;
- (id)self;
- (struct _NSZone *)zone;
- (id)performSelector:(SEL)arg1;
- (id)performSelector:(SEL)arg1 withObject:(id)arg2;
- (id)performSelector:(SEL)arg1 withObject:(id)arg2 withObject:(id)arg3;
- (BOOL)isProxy;
- (BOOL)isKindOfClass:(Class)arg1;
- (BOOL)isMemberOfClass:(Class)arg1;
- (BOOL)conformsToProtocol:(id)arg1;
- (BOOL)respondsToSelector:(SEL)arg1;
- (id)retain;
- (oneway void)release;
- (id)autorelease;
- (unsigned int)retainCount;
- (id)description;
- (id)debugDescription;
@end

@protocol VSRecognitionModelDataProvider <NSObject>
- (int)valueCountForClassWithIdentifier:(id)arg1 inModelWithIdentifier:(id)arg2;

@optional
- (id)valueAtIndex:(int)arg1 forClassWithIdentifier:(id)arg2 inModelWithIdentifier:(id)arg3;
- (BOOL)getValue:(id *)arg1 weight:(int *)arg2 atIndex:(int)arg3 forClassWithIdentifier:(id)arg4 inModelWithIdentifier:(id)arg5;
- (id)phoneticValueAtIndex:(int)arg1 forClassWithIdentifier:(id)arg2 inModelWithIdentifier:(id)arg3;
- (id)cacheValidityIdentifier;
- (BOOL)isCacheValidityIdentifierValid:(id)arg1;
- (void)beginReportingChanges;
- (void)stopReportingChanges;
@end

@protocol VSRecognitionResultHandler <NSObject>

@optional
- (id)actionForRecognitionResult:(id)arg1;
- (id)actionForRecognitionResults:(id)arg1;
@end

@interface NSArray (VSRecognitionSessionKeywords)
- (id)_scrambledKeywordsAndAddToSet:(id)arg1;
- (id)_nextKeywordUsingCursors:(struct __CFDictionary *)arg1;
@end

@interface NSAttributedString (VSSpeechAdditions)
+ (id)attributedStringWithFormatAndAttributes:(id)arg1;
@end

@interface NSMutableAttributedString (VSSpeechAdditions)
- (void)appendString:(id)arg1 withAttributes:(id)arg2;
@end

@interface VSAssetUpdateListener : NSObject
{
    BOOL _isListening;
    id _assetCleanupTimer;
}

+ (id)sharedListener;
- (id)init;
- (id)_initShared;
- (void)dealloc;
- (void)_rescheduleAssetCleanup;
- (void)startListening;
- (void)stopListening;
- (void)_flushLanguageChanges;
- (void)_cleanupAssets;
- (void)_spokenLanguageChanged:(id)arg1;
- (void)_updateNextCleanupDate;
- (void)_scheduleNextCleanupForDate:(id)arg1;
- (void)_cancelAssetCleanupTimer;

@end

@interface VSCacheUpdateListener : NSObject
{
    NSLock *_lock;
    NSMutableArray *_updateRequestQueue;
    NSDictionary *_dataProviders;
    NSTimer *_flushTimer;
    BOOL _isListening;
}

+ (id)sharedListener;
+ (id)sharedListenerIfExists;
- (id)init;
- (id)_initShared;
- (void)dealloc;
- (void)startListening;
- (void)stopListening;
- (void)performUpdateForModelIdentifier:(id)arg1 classIdentifier:(id)arg2;
- (void)_spokenLanguageChanged:(id)arg1;
- (void)_enqueueRequest:(id)arg1;
- (void)_flush;

@end

@interface VSCacheUpdateRequest : NSObject
{
    NSString *_modelID;
    NSString *_classID;
}

- (id)initWithModelIdentifier:(id)arg1 classIdentifier:(id)arg2;
- (void)dealloc;
- (id)modelIdentifier;
- (id)classIdentifier;
- (id)coalescedRequest:(id)arg1;
- (id)description;

@end

@interface VSFormatArgument : NSObject
{
    NSString *formatSpecifier;
    NSDictionary *attributes;
    NSString *formattedArg;
}

- (void)dealloc;

@end

@class VSRecognitionSession;

@interface VSRecognitionAction : NSObject
{
    NSString *_resultString;
    NSString *_statusString;
    union {
        NSString *stringValue;
        NSAttributedString *attributedStringValue;
    } _spokenString;
    VSRecognitionSession *_session;
    unsigned int _spokenStringIsAttributed:1;
}

- (id)_session;
- (void)_setSession:(id)arg1;
- (void)dealloc;
- (id)resultDisplayString;
- (void)setResultDisplayString:(id)arg1;
- (id)statusDisplayString;
- (void)setStatusDisplayString:(id)arg1;
- (id)spokenFeedbackString;
- (void)setSpokenFeedbackString:(id)arg1;
- (id)spokenFeedbackAttributedString;
- (void)setSpokenFeedbackAttributedString:(id)arg1;
- (int)completionType;
- (id)perform;
- (id)cancel;
- (void)completeWithNextAction:(id)arg1 error:(id)arg2;
- (BOOL)_hasDeferredStartCallback;
- (BOOL)sensitiveActionsEnabled;
- (void)_continueAfterDeferredStart;

@end

@interface VSRecognitionRecognizeAction : VSRecognitionAction
{
    NSString *_modelIdentifier;
    NSArray *_keywords;
    void *_recognition;
    NSArray *_results;
    NSString *_debugDumpPath;
    NSString *_audioInputPath;
    double _levelInterval;
    struct {
        unsigned int debugDumpEnabled:1;
        unsigned int preferredEngine:2;
        unsigned int resetEngine:1;
        unsigned int bluetoothAllowed:1;
        unsigned int hasStarted:1;
    } _recognizeFlags;
}

- (id)initWithModelIdentifier:(id)arg1;
- (void)dealloc;
- (int)completionType;
- (id)modelIdentifier;
- (BOOL)_isRecognizing;
- (BOOL)_isActivelyRecognizing;
- (BOOL)_hasDeferredStartCallback;
- (BOOL)_setBluetoothInputAllowed:(BOOL)arg1;
- (BOOL)_setInputLevelUpdateInterval:(double)arg1;
- (float)_inputLevel;
- (id)_keywords;
- (id)_keywordAtIndex:(int)arg1;
- (int)_keywordCount;
- (BOOL)_keywordIndexChanged;
- (BOOL)_setDebugDumpEnabled:(BOOL)arg1 dumpPath:(id)arg2;
- (BOOL)_setDebugDumpEnabled:(BOOL)arg1;
- (BOOL)_setDebugDumpPath:(id)arg1;
- (id)_debugDumpPath;
- (BOOL)_setPreferredEngine:(int)arg1;
- (BOOL)_setAudioInputPath:(id)arg1;
- (BOOL)_setEngineResetRequired:(BOOL)arg1;
- (struct __VSRecognition *)_createRecognitionInstanceWithCallbacks:(CDStruct_90f67059 *)arg1 info:(void *)arg2;
- (void)_configureNewRecognitionInstance;
- (id)perform;
- (id)cancel;
- (void)_releaseFromPrepare;
- (void)_continueAfterDeferredStart;
- (id)_actionForEmptyResults;
- (void)_setResults:(id)arg1;
- (void)_reset;
- (void)_handleRecognitionPrepared:(struct __VSRecognition *)arg1;
- (void)_handleRecognitionStarted:(struct __VSRecognition *)arg1;
- (void)_handleRecognitionCompleted:(struct __VSRecognition *)arg1 withResults:(struct __CFArray *)arg2 error:(struct __CFError *)arg3;
- (void)_handledThreadedResults:(id)arg1 nextAction:(id)arg2;

@end

@interface VSRecognitionConfirmAction : VSRecognitionRecognizeAction
{
    VSRecognitionAction *_confirmedAction;
    VSRecognitionAction *_deniedAction;
    struct {
        unsigned int initializing:1;
        unsigned int confirmed:1;
    } _confirmFlags;
}

- (id)init;
- (id)initWithModelIdentifier:(id)arg1;
- (void)dealloc;
- (int)completionType;
- (void)_setConfirmed:(BOOL)arg1;
- (void)setConfirmedAction:(id)arg1;
- (id)confirmedAction;
- (void)setDeniedAction:(id)arg1;
- (id)deniedAction;

@end

@interface VSRecognitionDisambiguateAction : VSRecognitionRecognizeAction
{
    NSString *_repeatedSpokenFeedbackString;
    NSString *_sequenceTag;
    NSMutableDictionary *_knownValues;
    NSMutableDictionary *_knownPhoneticValues;
    NSMutableDictionary *_ambiguousValues;
    NSMutableDictionary *_ambiguousPhoneticValues;
    void *_context;
}

- (void)dealloc;
- (int)completionType;
- (void)setRepeatedSpokenFeedbackString:(id)arg1;
- (id)repeatedSpokenFeedbackString;
- (id)sequenceTag;
- (void)setSequenceTag:(id)arg1;
- (id)knownValueForClassIdentifier:(id)arg1;
- (void)setKnownValue:(id)arg1 phoneticValue:(id)arg2 forClassIdentifier:(id)arg3;
- (id)knownValuesForClassIdentifier:(id)arg1;
- (void)setKnownValues:(id)arg1 phoneticValues:(id)arg2 forClassIdentifier:(id)arg3;
- (id)ambiguousValuesForClassIdentifier:(id)arg1;
- (void)setAmbiguousValues:(id)arg1 phoneticValues:(id)arg2 forClassIdentifier:(id)arg3;
- (id)_keywords;
- (BOOL)_keywordIndexChanged;
- (void)setKeywords:(id)arg1;
- (struct __VSRecognitionDisambiguationContext *)_disambiguationContext;
- (struct __VSRecognition *)_createRecognitionInstanceWithCallbacks:(CDStruct_90f67059 *)arg1 info:(void *)arg2;
- (id)_actionForEmptyResults;

@end

@interface VSRecognitionResult : NSObject
{
}

+ (void)initialize;
+ (id)recognitionResultWithModelIdentifier:(id)arg1 classIdentifiers:(id)arg2 values:(id)arg3;
- (id)init;
- (BOOL)isEqual:(id)arg1;
- (unsigned int)hash;
- (id)retain;
- (oneway void)release;
- (unsigned int)retainCount;
- (id)recognitionResultByReplacingValueForClassIdentifier:(id)arg1 withValue:(id)arg2;
- (id)modelIdentifier;
- (int)elementCount;
- (BOOL)getElementClassIdentifier:(id *)arg1 value:(id *)arg2 atIndex:(int)arg3;
- (id)valueOfFirstElementWithClassIdentifier:(id)arg1;
- (id)createHandler;
- (void)setRecognitionAction:(id)arg1;
- (id)recognitionAction;
- (id)description;

@end

@interface VSRecognitionResultHandlingRequest : NSObject
{
    id <VSRecognitionResultHandler> _handler;
    NSArray *_results;
    VSRecognitionAction *_action;
}

- (id)initWithHandler:(id)arg1 results:(id)arg2;
- (void)dealloc;
- (id)results;
- (id)handler;
- (void)setNextAction:(id)arg1;
- (id)nextAction;

@end

@interface VSRecognitionResultHandlingThread : NSObject
{
    id _delegate;
    NSMutableArray *_requests;
    NSConditionLock *_lock;
    struct {
        unsigned int running:1;
        unsigned int delegateDidHandleResults:1;
        unsigned int valid:1;
    } _resultHandlingFlags;
}

- (id)init;
- (void)dealloc;
- (void)setDelegate:(id)arg1;
- (void)handleResults:(id)arg1 withHandler:(id)arg2;
- (void)invalidate;
- (void)_notifyRequestHandled:(id)arg1;
- (void)_handleRequests;

@end

@class VSSpeechSynthesizer;

@interface VSRecognitionSession : NSObject
{
    NSString *_modelIdentifier;
    void *_keepAlive;
    id _delegate;
    VSRecognitionAction *_currentAction;
    NSArray *_topLevelKeywords;
    id _handlingThread;
    VSSpeechSynthesizer *_synthesizer;
    NSString *_languageID;
    NSString *_debugDumpPath;
    NSString *_audioInputPath;
    double _levelInterval;
    unsigned int _keywordPhase;
    struct {
        unsigned int delegateWillBegin:1;
        unsigned int delegateBegin:1;
        unsigned int delegateOpenURL:1;
        unsigned int delegateFinishedSpeaking:1;
        unsigned int delegateComplete:1;
        unsigned int debugDumpEnabled:1;
        unsigned int preferredEngine:2;
        unsigned int performHandlerActions:1;
        unsigned int allowSensitiveActions:1;
        unsigned int bluetoothAllowed:1;
        unsigned int resetNextAction:1;
        unsigned int isSpeaking:1;
        unsigned int actionBegan:1;
        unsigned int actionBeginning:1;
        unsigned int actionBeginDeferred:1;
        unsigned int invalid:1;
        unsigned int observeKeywordChange:1;
    } _sessionFlags;
}

- (void)_init;
- (id)init;
- (id)initWithModelIdentifier:(id)arg1;
- (void)dealloc;
- (void)setDelegate:(id)arg1;
- (id)beginNextAction;
- (id)reset;
- (BOOL)isRecognizing;
- (BOOL)isActivelyRecognizing;
- (BOOL)isFinished;
- (BOOL)isValid;
- (BOOL)hasDeferredAction;
- (BOOL)isBusy;
- (BOOL)nextActionWillTerminateSession;
- (BOOL)nextActionWillRecognize;
- (void)setSensitiveActionsEnabled:(BOOL)arg1;
- (BOOL)sensitiveActionsEnabled;
- (BOOL)setBluetoothInputAllowed:(BOOL)arg1;
- (id)cancelMaintainingKeepAlive:(BOOL)arg1;
- (id)cancel;
- (void)_actionCompleted:(id)arg1 nextAction:(id)arg2 error:(id)arg3;
- (BOOL)_actionStarted:(id)arg1;
- (void)_notifyDelegateActionStarted;
- (id)_notifyDelegateOpenURL:(id)arg1;
- (void)_setAction:(id)arg1;
- (id)_currentRecognizeAction;
- (id)_recognitionResultHandlingThread;
- (void)recognitionResultHandlingThread:(id)arg1 didHandleResults:(id)arg2 nextAction:(id)arg3;
- (id)spokenFeedbackString;
- (id)spokenFeedbackAttributedString;
- (id)displayResultString;
- (id)displayStatusString;
- (void)setInputLevelUpdateInterval:(double)arg1;
- (float)inputLevel;
- (void)setKeywordPhase:(unsigned int)arg1;
- (id)keywordAtIndex:(int)arg1;
- (int)keywordCount;
- (struct __CFDictionary *)_createKeywordIndex;
- (id)_createPhaseSortedKeywordsFromArray:(id)arg1;
- (id)_topLevelKeywords;
- (id)_keywordsForModelIdentifier:(id)arg1;
- (void)_keywordIndexChanged;
- (id)beginSpeakingFeedbackString;
- (id)beginSpeakingString:(id)arg1;
- (id)_beginSpeakingAttributedString:(id)arg1;
- (id)_beginSpeakingString:(id)arg1 attributedString:(id)arg2;
- (void)_notifyDelegateFinishedSpeakingWithError:(id)arg1;
- (void)speechSynthesizer:(id)arg1 didFinishSpeaking:(BOOL)arg2 withError:(id)arg3;
- (BOOL)setDebugDumpEnabled:(BOOL)arg1;
- (id)debugDumpPath;
- (BOOL)setNextRecognitionAudioInputPath:(id)arg1;
- (BOOL)setNextRecognitionRequiresReset:(BOOL)arg1;
- (BOOL)setPreferredEngine:(int)arg1;
- (void)setPerformRecognitionHandlerActions:(BOOL)arg1;

@end

@interface VSRecognitionSpeakAction : VSRecognitionAction
{
    BOOL _shouldTerminate;
}

- (id)initWithSpokenFeedbackString:(id)arg1 willTerminate:(BOOL)arg2;
- (int)completionType;
- (id)perform;

@end

@interface VSRecognitionURLAction : VSRecognitionAction
{
    NSURL *_url;
}

- (void)dealloc;
- (int)completionType;
- (void)setURL:(id)arg1;
- (id)URL;
- (id)perform;

@end

@interface VSSpeechSynthesizer : NSObject
{
    void *_speechJob;
    void *_keepAlive;
    id _delegate;
    NSString *_voice;
    int _footprint;
    float _rate;
    float _pitch;
    float _volume;
    struct {
        unsigned int delegateStart:1;
        unsigned int delegateFinish:1;
        unsigned int delegateFinishWithPhonemesSpoken:1;
        unsigned int delegatePause:1;
        unsigned int delegateContinue:1;
        unsigned int delegateWillSpeak:1;
        unsigned int willUseInput:1;
    } _synthesizerFlags;
}

+ (id)availableVoices;
+ (id)availableVoicesForLanguageCode:(id)arg1;
+ (id)availableLanguageCodes;
+ (BOOL)isSystemSpeaking;
+ (void)_localeDidChange;
- (id)init;
- (id)initForInputFeedback;
- (void)dealloc;
- (void)setDelegate:(id)arg1;
- (id)startSpeakingString:(id)arg1;
- (id)startSpeakingString:(id)arg1 toURL:(id)arg2;
- (id)startSpeakingString:(id)arg1 withLanguageCode:(id)arg2;
- (id)startSpeakingString:(id)arg1 attributedString:(id)arg2 toURL:(id)arg3 withLanguageCode:(id)arg4;
- (id)startSpeakingString:(id)arg1 toURL:(id)arg2 withLanguageCode:(id)arg3;
- (id)startSpeakingAttributedString:(id)arg1;
- (id)startSpeakingAttributedString:(id)arg1 toURL:(id)arg2;
- (id)startSpeakingAttributedString:(id)arg1 toURL:(id)arg2 withLanguageCode:(id)arg3;
- (id)stopSpeakingAtNextBoundary:(int)arg1;
- (id)stopSpeakingAtNextBoundary:(int)arg1 synchronously:(BOOL)arg2;
- (id)pauseSpeakingAtNextBoundary:(int)arg1;
- (id)pauseSpeakingAtNextBoundary:(int)arg1 synchronously:(BOOL)arg2;
- (id)continueSpeaking;
- (BOOL)isSpeaking;
- (id)speechString;
- (float)rate;
- (id)setRate:(float)arg1;
- (float)minimumRate;
- (float)maximumRate;
- (id)setPitch:(float)arg1;
- (float)pitch;
- (id)setVolume:(float)arg1;
- (float)volume;
- (void)setVoice:(id)arg1;
- (id)voice;
- (void)setFootprint:(int)arg1;
- (int)footprint;
- (void)setMaintainPersistentConnection:(BOOL)arg1;
- (void)_handleSpeechStarted:(struct __VSSpeech *)arg1;
- (void)_handleSpeechPaused:(struct __VSSpeech *)arg1;
- (void)_handleSpeechContinued:(struct __VSSpeech *)arg1;
- (void)_handleSpeech:(struct __VSSpeech *)arg1 completed:(BOOL)arg2 phonemesSpoken:(struct __CFString *)arg3 withError:(id)arg4;
- (void)_handleSpeech:(struct __VSSpeech *)arg1 willSpeakMarkType:(int)arg2 inRange:(CDStruct_1ef3fb1f)arg3;

@end

@interface VSTextPreProcessor : NSObject
{
    NSArray *_rules;
    NSString *_languageID;
    struct __CFStringTokenizer *_tokenizer;
}

- (id)initWithContentsOfPath:(id)arg1 languageIdentifier:(id)arg2;
- (void)dealloc;
- (id)processedTextFromString:(id)arg1;

@end

@interface VSTextPreProcessorRule : NSObject
{
    NSString *_matchPattern;
    NSString *_replacement;
    BOOL _caseSensitive;
    BOOL _eatPunctuation;
}

- (id)initWithDictionaryRepresentation:(id)arg1;
- (void)dealloc;
- (id)matchedString:(id)arg1 forTokenInRange:(CDStruct_1ef3fb1f *)arg2;

@end

